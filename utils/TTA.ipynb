{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론 전용 스크립트\n",
    "\n",
    "체크포인트를 불러와서 추론만 수행합니다 (TTA 지원).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import albumentations as A\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "import ttach as tta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Constants & 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 클래스 정의\n",
    "CLASSES = [\n",
    "    'finger-1', 'finger-2', 'finger-3', 'finger-4', 'finger-5',\n",
    "    'finger-6', 'finger-7', 'finger-8', 'finger-9', 'finger-10',\n",
    "    'finger-11', 'finger-12', 'finger-13', 'finger-14', 'finger-15',\n",
    "    'finger-16', 'finger-17', 'finger-18', 'finger-19', 'Trapezium',\n",
    "    'Trapezoid', 'Capitate', 'Hamate', 'Scaphoid', 'Lunate',\n",
    "    'Triquetrum', 'Pisiform', 'Radius', 'Ulna',\n",
    "]\n",
    "\n",
    "CLASS2IND = {v: i for i, v in enumerate(CLASSES)}\n",
    "IND2CLASS = {v: k for k, v in CLASS2IND.items()}\n",
    "\n",
    "# 경로 설정\n",
    "SAVED_DIR = \"checkpoints\"\n",
    "MODEL_NAME = \"efficientnetb3_unetplusplus_9736.pt\"\n",
    "IMAGE_ROOT = \"../data/test/DCM\"  # 테스트 데이터 경로를 입력하세요\n",
    "\n",
    "# 추론 설정\n",
    "BATCH_SIZE = 2\n",
    "NUM_WORKERS = 2\n",
    "THRESHOLD = 0.5\n",
    "OUTPUT_CSV = \"output_left.csv\"\n",
    "USE_TTA = True  # TTA 사용 여부\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_mask_to_rle(mask):\n",
    "    \"\"\"\n",
    "    mask: numpy array binary mask \n",
    "    1 - mask \n",
    "    0 - background\n",
    "    Returns encoded run length \n",
    "    \"\"\"\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "\n",
    "def decode_rle_to_mask(rle, height, width):\n",
    "    \"\"\"\n",
    "    RLE로 인코딩된 결과를 mask map으로 복원합니다.\n",
    "    \"\"\"\n",
    "    s = rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(height * width, dtype=np.uint8)\n",
    "    \n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    \n",
    "    return img.reshape(height, width)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class XRayInferenceDataset(Dataset):\n",
    "    def __init__(self, image_root, transforms=None):\n",
    "        \"\"\"\n",
    "        추론용 Dataset 클래스\n",
    "        \"\"\"\n",
    "        self.image_root = image_root\n",
    "        \n",
    "        # 이미지 파일 목록 생성\n",
    "        pngs = {\n",
    "            os.path.relpath(os.path.join(root, fname), start=image_root)\n",
    "            for root, _dirs, files in os.walk(image_root)\n",
    "            for fname in files\n",
    "            if os.path.splitext(fname)[1].lower() == \".png\"\n",
    "        }\n",
    "        \n",
    "        _filenames = np.array(sorted(pngs))\n",
    "        self.filenames = _filenames\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        # 핸드 타입(Left/Right) 자동 매핑 로직\n",
    "        # Test 데이터도 Train과 동일한 규칙(폴더 내 정렬 시 1번=Right, 2번=Left)을 따른다고 가정\n",
    "        self.hand_side_map = {}\n",
    "        \n",
    "        files_by_folder = defaultdict(list)\n",
    "        for fname in _filenames:\n",
    "            folder = os.path.dirname(fname)\n",
    "            files_by_folder[folder].append(fname)\n",
    "            \n",
    "        for folder, files in files_by_folder.items():\n",
    "            files.sort()\n",
    "            if len(files) > 0:\n",
    "                self.hand_side_map[files[0]] = 'Right'\n",
    "            if len(files) > 1:\n",
    "                self.hand_side_map[files[1]] = 'Left'\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        image_name = self.filenames[item]\n",
    "        image_path = os.path.join(self.image_root, image_name)\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # 원본 이미지 크기 저장 (나중에 복원 시 필요할 수 있음)\n",
    "        original_shape = image.shape[:2]\n",
    "        \n",
    "        image = image / 255.\n",
    "        \n",
    "        # --- 오른손(Right)일 경우 Flip 적용 ---\n",
    "        hand_side = self.hand_side_map.get(image_name, 'Unknown')\n",
    "        \n",
    "        if hand_side == 'Right':\n",
    "            # 학습 때와 똑같이 좌우 반전시켜 모델에 넣습니다.\n",
    "            image = cv2.flip(image, 1) \n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            inputs = {\"image\": image}\n",
    "            result = self.transforms(**inputs)\n",
    "            image = result[\"image\"]\n",
    "\n",
    "        # to tensor\n",
    "        image = image.transpose(2, 0, 1)\n",
    "        image = torch.from_numpy(image).float()\n",
    "            \n",
    "        # hand_side 정보도 같이 반환해야 나중에 결과를 다시 뒤집을 수 있습니다.\n",
    "        return image, image_name, hand_side\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import ttach as tta\n",
    "\n",
    "def test_single_image(model, image_tensor, hand_side, use_tta=False):\n",
    "    model.eval()\n",
    "    \n",
    "    img = image_tensor.unsqueeze(0).cuda()  # (1, C, H, W)\n",
    "    \n",
    "    # TTA 적용\n",
    "    if use_tta:\n",
    "        # TTA 변환 정의 (Scale 추가)\n",
    "        tta_transforms = tta.Compose([\n",
    "            tta.Scale(scales=[0.75, 1.0, 1.25], \n",
    "                      interpolation=\"bilinear\"), # Multi-scale 적용\n",
    "        ])\n",
    "        \n",
    "        # 모델을 TTA 래퍼로 감싸기\n",
    "        # merge_mode='mean': 결과를 평균내어 합침\n",
    "        tta_model = tta.SegmentationTTAWrapper(model, tta_transforms, merge_mode='mean')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = tta_model(img)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            output = model(img)\n",
    "    \n",
    "    # 크기 복원 (2048x2048)\n",
    "    # TTA를 썼더라도 최종 output은 입력 img 크기와 같으므로, \n",
    "    # 원본 해상도(2048)로 복원하는 과정은 동일하게 유지합니다.\n",
    "    #output = F.interpolate(output, size=(2048, 2048), mode=\"bilinear\", align_corners=False)\n",
    "    output = torch.sigmoid(output)\n",
    "    \n",
    "    # 오른손(Right)인 경우, 예측된 마스크를 다시 원래대로 뒤집음 (Unflip)\n",
    "    if hand_side == 'Right':\n",
    "        output = torch.flip(output, [3])  # 좌우 반전 (W 차원)\n",
    "    \n",
    "    return output.squeeze(0)  # (Class, H, W)\n",
    "'''\n",
    "'''\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def test_single_image(model, image_tensor, hand_side, use_tta=False):\n",
    "    model.eval()\n",
    "    \n",
    "    # (C, H, W) -> (1, C, H, W)\n",
    "    img = image_tensor.unsqueeze(0).cuda()\n",
    "    \n",
    "    # 기준 사이즈 (현재 들어온 이미지의 크기)\n",
    "    base_h, base_w = img.shape[2], img.shape[3]\n",
    "    \n",
    "    if use_tta:\n",
    "        # 1. 사용할 스케일 정의 (질문하신 수치 반영)\n",
    "        scales = [0.796875, 1.0, 1.203125] \n",
    "        \n",
    "        # 결과를 누적할 변수 초기화\n",
    "        logit_sum = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for scale in scales:\n",
    "                # 2. 입력 이미지 리사이즈 (Scale 적용)\n",
    "                # 스케일에 맞춰 타겟 H, W 계산\n",
    "                target_h = int(base_h * scale)\n",
    "                target_w = int(base_w * scale)\n",
    "                \n",
    "                # 이미지를 줄이거나 키워서 모델에 넣음\n",
    "                scaled_img = F.interpolate(img, size=(target_h, target_w), mode='bilinear', align_corners=False)\n",
    "                \n",
    "                # 3. 모델 추론\n",
    "                output = model(scaled_img)\n",
    "                \n",
    "                # 4. 결과 복원 (Restore)\n",
    "                # 합치기(Merge) 위해 다시 원래 base 사이즈로 되돌림\n",
    "                # Logit(실수) 상태에서 Bilinear로 복원해야 경계가 부드러움\n",
    "                output = F.interpolate(output, size=(base_h, base_w), mode='bilinear', align_corners=False)\n",
    "                \n",
    "                # 5. 누적\n",
    "                logit_sum += output\n",
    "        \n",
    "        # 6. 평균 (Mean Merge)\n",
    "        output = logit_sum / len(scales)\n",
    "        \n",
    "    else:\n",
    "        # TTA 안 쓸 때는 그냥 추론\n",
    "        with torch.no_grad():\n",
    "            output = model(img)\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 최종 후처리 (Resize -> Sigmoid -> Unflip)\n",
    "    # -----------------------------------------------------------\n",
    "\n",
    "    # 1. 최종 제출 크기(2048)로 복원\n",
    "    # TTA 과정에서 base_size로 합쳤으므로, 마지막에 2048로 키워줍니다.\n",
    "    output = F.interpolate(output, size=(2048, 2048), mode='bilinear', align_corners=False)\n",
    "    \n",
    "    # 2. Sigmoid 적용 (Logit -> Probability)\n",
    "    output = torch.sigmoid(output)\n",
    "    \n",
    "    # 3. 오른손(Right)인 경우 다시 뒤집기 (Unflip)\n",
    "    if hand_side == 'Right':\n",
    "        output = torch.flip(output, [3])  # 좌우 반전 (W 차원)\n",
    "    \n",
    "    return output.squeeze(0)  # (Class, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, data_loader, thr=0.5, use_tta=False):\n",
    "    \"\"\"\n",
    "    모델을 사용하여 추론을 수행합니다 (TTA 지원).\n",
    "    \"\"\"\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    rles = []\n",
    "    filename_and_class = []\n",
    "    \n",
    "    print(f\"TTA 사용: {use_tta}\")\n",
    "    \n",
    "    for step, (images, image_names, hand_sides) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        # 배치를 개별 이미지로 처리 (TTA를 위해)\n",
    "        for img, image_name, hand_side in zip(images, image_names, hand_sides):\n",
    "            # 단일 이미지 추론 (TTA 적용)\n",
    "            output = test_single_image(model, img, hand_side, use_tta=use_tta)\n",
    "            \n",
    "            # Threshold 적용 -> Numpy 변환 (Class, H, W)\n",
    "            output = (output > thr).detach().cpu().numpy().astype(np.uint8)\n",
    "            \n",
    "            # 각 클래스별로 RLE 인코딩\n",
    "            for c, segm in enumerate(output):\n",
    "                # segm shape: (H, W)\n",
    "                rle = encode_mask_to_rle(segm)\n",
    "                rles.append(rle)\n",
    "                filename_and_class.append(f\"{IND2CLASS[c]}_{image_name}\")\n",
    "                    \n",
    "    return rles, filename_and_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 체크포인트 로딩\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "체크포인트 로딩: checkpoints/efficientnetb3_unetplusplus_9736.pt\n",
      "체크포인트 로딩 완료\n"
     ]
    }
   ],
   "source": [
    "# 체크포인트 경로 확인\n",
    "checkpoint_path = os.path.join(SAVED_DIR, MODEL_NAME)\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    raise FileNotFoundError(f\"체크포인트 파일을 찾을 수 없습니다: {checkpoint_path}\")\n",
    "\n",
    "print(f\"체크포인트 로딩: {checkpoint_path}\")\n",
    "model = torch.load(checkpoint_path)\n",
    "model.eval()\n",
    "print(\"체크포인트 로딩 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 경로: ../data/test/DCM\n",
      "테스트 데이터 개수: 288\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 경로 확인\n",
    "if not os.path.exists(IMAGE_ROOT):\n",
    "    raise FileNotFoundError(f\"테스트 데이터 경로를 찾을 수 없습니다: {IMAGE_ROOT}\")\n",
    "\n",
    "print(f\"테스트 데이터 경로: {IMAGE_ROOT}\")\n",
    "\n",
    "# 데이터 변환 정의\n",
    "transform = A.Resize(2048, 2048)\n",
    "\n",
    "# Dataset 및 DataLoader 생성\n",
    "test_dataset = XRayInferenceDataset(image_root=IMAGE_ROOT, transforms=transform)\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "print(f\"테스트 데이터 개수: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론 수행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추론 중...\n",
      "TTA 사용: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df25b62258dd429d8fb55e65e134cb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추론 완료. 총 8352개의 마스크 생성됨\n"
     ]
    }
   ],
   "source": [
    "print(\"추론 중...\")\n",
    "rles, filename_and_class = test(model, test_loader, thr=THRESHOLD, use_tta=USE_TTA)\n",
    "\n",
    "print(f\"추론 완료. 총 {len(rles)}개의 마스크 생성됨\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 결과 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과 저장 완료: output_left.csv\n",
      "==================================================\n",
      "추론 완료!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일로 저장\n",
    "classes, filename = zip(*[x.split(\"_\", 1) for x in filename_and_class])\n",
    "image_name = [os.path.basename(f) for f in filename]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"image_name\": image_name,\n",
    "    \"class\": classes,\n",
    "    \"rle\": rles,\n",
    "})\n",
    "\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"결과 저장 완료: {OUTPUT_CSV}\")\n",
    "print(\"=\" * 50)\n",
    "print(\"추론 완료!\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
