{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1709245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 사용자 정의 라이브러리\n",
    "from custom_dataset import XRayDataset, CLASSES \n",
    "from SAM2UNet import SAM2UNet\n",
    "\n",
    "# 시드 고정 (선택 사항)\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "print(\"Libraries loaded & Seed set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30897f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 경로\n",
    "ROOT_IMG = \"../data/train/DCM\" \n",
    "ROOT_LBL = \"../data/train/outputs_json\"\n",
    "\n",
    "# 2. 모델 체크포인트 경로\n",
    "MODEL_PATH = \"../sam2_unet_result_checkpoints/experiment2.pth\"\n",
    "HIERA_PATH = \"../checkpoints/sam2_hiera_large.pt\"\n",
    "\n",
    "# 3. 디바이스 설정\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 4. 데이터셋 변환 (Validation/Test용)\n",
    "# 학습 때 사용한 크기와 맞춰줘야 함\n",
    "IMG_SIZE = 1024 \n",
    "valid_transform = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Image Size: {IMG_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e88a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_class_wise_overlap_target(target):\n",
    "    \"\"\"\n",
    "    각 클래스별로 '다른 뼈와 겹치는 영역'만 남기고 나머지는 0으로 만드는 함수\n",
    "    Args:\n",
    "        target: [Batch, 29, H, W] (Binary Mask)\n",
    "    Returns:\n",
    "        class_wise_overlap: 겹치는 부위만 남은 클래스별 마스크\n",
    "        global_overlap_mask: 전체 이미지에서 겹침이 발생한 모든 영역\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # 1. 픽셀별로 뼈가 몇 개 있는지 계산\n",
    "        count_map = torch.sum(target, dim=1, keepdim=True)\n",
    "        # 2. 뼈가 2개 이상 있는 곳 찾기 (Overlap)\n",
    "        global_overlap_mask = (count_map >= 2.0).float()\n",
    "        # 3. 각 클래스 마스크에 Overlap 마스크 적용\n",
    "        class_wise_overlap = target * global_overlap_mask\n",
    "    return class_wise_overlap, global_overlap_mask\n",
    "\n",
    "def generate_masked_edge_target(target):\n",
    "    \"\"\"\n",
    "    겹치는 영역 내부에 있는 경계선(Edge)만 추출\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        dilated = F.max_pool2d(target, kernel_size=3, stride=1, padding=1)\n",
    "        eroded = -F.max_pool2d(-target, kernel_size=3, stride=1, padding=1)\n",
    "        raw_edges = dilated - eroded\n",
    "        \n",
    "        count_map = torch.sum(dilated, dim=1, keepdim=True)\n",
    "        overlap_mask = (count_map >= 2.0).float()\n",
    "        \n",
    "        masked_edges = raw_edges * overlap_mask\n",
    "    return masked_edges\n",
    "\n",
    "def generate_inner_edge_target(target):\n",
    "    \"\"\"\n",
    "    뼈의 안쪽으로 파고드는(침식 기반) 내부 경계 생성\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # kernel=5로 조금 더 깊게 침식\n",
    "        eroded = -F.max_pool2d(-target, kernel_size=5, stride=1, padding=2)\n",
    "        inner_edges = target - eroded\n",
    "        \n",
    "        count_map = torch.sum(target, dim=1, keepdim=True)\n",
    "        overlap_mask = (count_map >= 2.0).float()\n",
    "        \n",
    "        masked_edges = inner_edges * overlap_mask\n",
    "    return masked_edges, overlap_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedaabe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_3_channels(dataset, index=0):\n",
    "    \"\"\"\n",
    "    Dataset의 __getitem__이 반환하는 3개 채널(예: 원본, Canny, Laplacian 등)을 시각화\n",
    "    \"\"\"\n",
    "    data = dataset[index]\n",
    "    image_tensor = data['image'] # (3, H, W)\n",
    "    image_np = image_tensor.permute(1, 2, 0).numpy()\n",
    "    \n",
    "    plt.figure(figsize=(20, 5))\n",
    "    titles = [\"Ch1: Original\", \"Ch2: Contrast/Edge\", \"Ch3: Boundary/Laplacian\"]\n",
    "    \n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 4, i+1)\n",
    "        plt.imshow(image_np[:, :, i], cmap='gray')\n",
    "        plt.title(titles[i])\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(image_np)\n",
    "    plt.title(\"Merged (RGB Model View)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def analyze_clahe_difference(dataset, index=0):\n",
    "    \"\"\"\n",
    "    CLAHE Clip Limit에 따른 이미지 변화량(Difference)을 히트맵으로 분석 함수\n",
    "    \"\"\"\n",
    "    data = dataset[index]\n",
    "    image_np = data['image'].permute(1, 2, 0).numpy()\n",
    "    \n",
    "    # 데이터셋 구성에 따라 인덱스가 다를 수 있음 (여기서는 예시)\n",
    "    orig = image_np[:, :, 0]\n",
    "    processed_1 = image_np[:, :, 1]\n",
    "    \n",
    "    diff = np.abs(processed_1 - orig)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 3, 1); plt.imshow(orig, cmap='gray'); plt.title(\"Original\")\n",
    "    plt.subplot(1, 3, 2); plt.imshow(processed_1, cmap='gray'); plt.title(\"Processed (CLAHE/Edge)\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(diff, cmap='magma')\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Difference Heatmap\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af5cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_all_classes_metric(model, dataset, index=0, device=DEVICE):\n",
    "    \"\"\"\n",
    "    특정 이미지에 대해 29개 클래스별 Dice Score, TP, FP, FN 픽셀 수를 계산하여 출력\n",
    "    \"\"\"\n",
    "    data = dataset[index]\n",
    "    image_tensor = data['image'].unsqueeze(0).to(device)\n",
    "    mask_tensor = data['label'].permute(2, 0, 1).unsqueeze(0).float().to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 모델의 리턴값 구조에 따라 수정 필요 (여기서는 4번째가 edge라고 가정)\n",
    "        output = model(image_tensor)\n",
    "        # SAM2UNet 리턴이 (mask, ds1, ds2, edge) 형태라면:\n",
    "        if isinstance(output, tuple):\n",
    "             _, _, _, pred_edge = output\n",
    "        else:\n",
    "            pred_edge = output\n",
    "\n",
    "        # 타겟 생성 (Overlap 기준)\n",
    "        target_edge, _ = generate_class_wise_overlap_target(mask_tensor) \n",
    "    \n",
    "    # Thresholding\n",
    "    pred_edge_binary = (torch.sigmoid(pred_edge) > 0.5).float()\n",
    "    \n",
    "    target_np = target_edge.squeeze(0).cpu().numpy()\n",
    "    pred_np = pred_edge_binary.squeeze(0).cpu().numpy()\n",
    "    \n",
    "    print(f\"--- [Image Index {index}] Class-wise Report ---\")\n",
    "    print(f\"{'ID':<4} {'Class Name':<15} {'Dice':<8} {'TP':<6} {'FP':<6} {'FN':<6} {'Status'}\")\n",
    "    \n",
    "    for idx, class_name in enumerate(CLASSES):\n",
    "        gt = target_np[idx] > 0.5\n",
    "        pred = pred_np[idx] > 0.5\n",
    "        \n",
    "        tp = np.sum(gt & pred)\n",
    "        fp = np.sum((~gt) & pred)\n",
    "        fn = np.sum(gt & (~pred))\n",
    "        \n",
    "        dice = (2 * tp) / (2 * tp + fp + fn + 1e-5)\n",
    "        \n",
    "        status = \"\"\n",
    "        if np.sum(gt) == 0 and np.sum(pred) > 0: status = \"⚠️ FP Warning\"\n",
    "        if np.sum(gt) == 0 and np.sum(pred) == 0: status = \"Clean\"\n",
    "        \n",
    "        print(f\"{idx+1:02d}   {class_name:<15} {dice:.4f}   {tp:<6} {fp:<6} {fn:<6} {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c850af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_strict_combined(model, dataset, index, device=DEVICE):\n",
    "    \"\"\"\n",
    "    모델의 예측 에러를 시각화\n",
    "    Red: 놓친 부분 (Miss/FN), Blue: 잘못 예측한 노이즈 (Noise/FP)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    data = dataset[index]\n",
    "    image_tensor = data['image'].unsqueeze(0).to(device)\n",
    "    target_origin = data['label'].permute(2, 0, 1).to(device) # (29, H, W)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        # 모델 출력 구조에 맞춰 로짓 선택 (여기서는 첫번째가 main mask라고 가정)\n",
    "        if isinstance(output, tuple): pred_logits = output[0]\n",
    "        else: pred_logits = output\n",
    "            \n",
    "        pred_probs = torch.sigmoid(pred_logits)\n",
    "        \n",
    "    pred_mask = (pred_probs[0] > 0.5).cpu().numpy()\n",
    "    gt_mask = (target_origin > 0).cpu().numpy()\n",
    "    image_np = data['image'].permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    # 에러 누적\n",
    "    total_miss = np.zeros(gt_mask.shape[1:], dtype=bool)\n",
    "    total_noise = np.zeros(gt_mask.shape[1:], dtype=bool)\n",
    "    \n",
    "    for c in range(29):\n",
    "        p, g = pred_mask[c], gt_mask[c]\n",
    "        total_miss |= (g & ~p) # FN\n",
    "        total_noise |= (~g & p) # FP\n",
    "\n",
    "    # 시각화용 오버레이\n",
    "    vis_miss = np.zeros((*total_miss.shape, 4)); vis_miss[total_miss] = [1, 0, 0, 0.6]\n",
    "    vis_noise = np.zeros((*total_noise.shape, 4)); vis_noise[total_noise] = [0, 0, 1, 0.6]\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1); plt.imshow(image_np); plt.title(\"Original\")\n",
    "    plt.subplot(1, 3, 2); plt.imshow(image_np); plt.imshow(vis_miss); plt.title(\"Miss (Red: FN)\")\n",
    "    plt.subplot(1, 3, 3); plt.imshow(image_np); plt.imshow(vis_noise); plt.title(\"Noise (Blue: FP)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca417d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_strict_combined(model, dataset, index, device=DEVICE):\n",
    "    \"\"\"\n",
    "    모델의 예측 에러를 시각화\n",
    "    Red: 놓친 부분 (Miss/FN), Blue: 잘못 예측한 노이즈 (Noise/FP)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    data = dataset[index]\n",
    "    image_tensor = data['image'].unsqueeze(0).to(device)\n",
    "    target_origin = data['label'].permute(2, 0, 1).to(device) # (29, H, W)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        # 모델 출력 구조에 맞춰 로짓 선택 (여기서는 첫번째가 main mask라고 가정)\n",
    "        if isinstance(output, tuple): pred_logits = output[0]\n",
    "        else: pred_logits = output\n",
    "            \n",
    "        pred_probs = torch.sigmoid(pred_logits)\n",
    "        \n",
    "    pred_mask = (pred_probs[0] > 0.5).cpu().numpy()\n",
    "    gt_mask = (target_origin > 0).cpu().numpy()\n",
    "    image_np = data['image'].permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    # 에러 누적\n",
    "    total_miss = np.zeros(gt_mask.shape[1:], dtype=bool)\n",
    "    total_noise = np.zeros(gt_mask.shape[1:], dtype=bool)\n",
    "    \n",
    "    for c in range(29):\n",
    "        p, g = pred_mask[c], gt_mask[c]\n",
    "        total_miss |= (g & ~p) # FN\n",
    "        total_noise |= (~g & p) # FP\n",
    "\n",
    "    # 시각화용 오버레이\n",
    "    vis_miss = np.zeros((*total_miss.shape, 4)); vis_miss[total_miss] = [1, 0, 0, 0.6]\n",
    "    vis_noise = np.zeros((*total_noise.shape, 4)); vis_noise[total_noise] = [0, 0, 1, 0.6]\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1); plt.imshow(image_np); plt.title(\"Original\")\n",
    "    plt.subplot(1, 3, 2); plt.imshow(image_np); plt.imshow(vis_miss); plt.title(\"Miss (Red: FN)\")\n",
    "    plt.subplot(1, 3, 3); plt.imshow(image_np); plt.imshow(vis_noise); plt.title(\"Noise (Blue: FP)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781f95d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if os.path.exists(ROOT_IMG) and os.path.exists(MODEL_PATH):\n",
    "        # 1. 데이터셋 및 모델 로드\n",
    "        dataset = XRayDataset(ROOT_IMG, ROOT_LBL, is_train=False, transforms=valid_transform)\n",
    "        \n",
    "        model = SAM2UNet(checkpoint_path=HIERA_PATH)\n",
    "        checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "        \n",
    "        # state_dict 키 처리 (저장 방식에 따라 다를 수 있음)\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "            \n",
    "        model.to(DEVICE)\n",
    "        print(\"모델 및 데이터셋 로드 완료\")\n",
    "        \n",
    "        # [A] 입력 데이터 확인 (채널별 시각화)\n",
    "        # visualize_3_channels(dataset, index=30)\n",
    "        \n",
    "        # [B] CLAHE 차이 분석\n",
    "        # analyze_clahe_difference(dataset, index=30)\n",
    "        \n",
    "        # [C] 전체 클래스 메트릭(Dice/TP/FP/FN) 리포트 출력\n",
    "        visualize_all_classes_metric(model, dataset, index=30, device=DEVICE)\n",
    "        \n",
    "        # [D] 엄격한 에러 시각화 (Miss vs Noise)\n",
    "        # visualize_strict_combined(model, dataset, index=30, device=DEVICE)\n",
    "        \n",
    "        # [E] 특정 뼈(예: Pisiform)의 겹침 영역 예측 성능 시각화\n",
    "        # visualize_class_wise_overlap_prediction(model, dataset, index=30, target_bones=[\"Pisiform\", \"Lunate\"], device=DEVICE)\n",
    "\n",
    "    else:\n",
    "        print(\"경로 오류: 데이터셋 폴더나 모델 파일을 찾을 수 없음\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
